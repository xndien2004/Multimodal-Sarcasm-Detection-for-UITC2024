{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:28:56.048442Z",
     "iopub.status.busy": "2024-11-11T17:28:56.047941Z",
     "iopub.status.idle": "2024-11-11T17:29:09.829854Z",
     "shell.execute_reply": "2024-11-11T17:29:09.828773Z",
     "shell.execute_reply.started": "2024-11-11T17:28:56.048381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install einops pyvi\n",
    "# !pip install --upgrade keras\n",
    "# !pip install -q -U tensorflow-addons\n",
    "# !pip install 'keras<3.0.0' mediapipe-model-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:09.832095Z",
     "iopub.status.busy": "2024-11-11T17:29:09.831786Z",
     "iopub.status.idle": "2024-11-11T17:29:28.512717Z",
     "shell.execute_reply": "2024-11-11T17:29:28.511764Z",
     "shell.execute_reply.started": "2024-11-11T17:29:09.832062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate, Add, Dot, Softmax, Lambda, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import resample\n",
    "import unicodedata\n",
    "import regex as re\n",
    "from pyvi import ViTokenizer\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.514466Z",
     "iopub.status.busy": "2024-11-11T17:29:28.513869Z",
     "iopub.status.idle": "2024-11-11T17:29:28.519218Z",
     "shell.execute_reply": "2024-11-11T17:29:28.518090Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.514429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.521911Z",
     "iopub.status.busy": "2024-11-11T17:29:28.521488Z",
     "iopub.status.idle": "2024-11-11T17:29:28.563079Z",
     "shell.execute_reply": "2024-11-11T17:29:28.562117Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.521859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VietnameseTextPreprocessor:\n",
    "    vowel_map = [\n",
    "        ['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "        ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "        ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "        ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "        ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "        ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "        ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "        ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "        ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "        ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "        ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "        ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']\n",
    "    ]\n",
    "\n",
    "    tone_map = ['', 'f', 's', 'r', 'x', 'j']\n",
    "    vowel_to_ids = {}\n",
    "\n",
    "    @classmethod\n",
    "    def initialize_vowel_to_ids(cls):\n",
    "        for i in range(len(cls.vowel_map)):\n",
    "            for j in range(len(cls.vowel_map[i]) - 1):\n",
    "                cls.vowel_to_ids[cls.vowel_map[i][j]] = (i, j)\n",
    "\n",
    "    @staticmethod\n",
    "    def unicode_normalize(text):\n",
    "        return unicodedata.normalize('NFC', text)\n",
    "\n",
    "    @classmethod\n",
    "    def is_valid_vietnamese_word(cls, word):\n",
    "        chars = list(word)\n",
    "        vowel_index = -1\n",
    "        for index, char in enumerate(chars):\n",
    "            x, y = cls.vowel_to_ids.get(char, (-1, -1))\n",
    "            if x != -1:\n",
    "                if vowel_index == -1:\n",
    "                    vowel_index = index\n",
    "                else:\n",
    "                    if index - vowel_index != 1:\n",
    "                        return False\n",
    "                    vowel_index = index\n",
    "        return True\n",
    "\n",
    "    @classmethod\n",
    "    def standardize_vietnamese_tone(cls, word):\n",
    "        if not cls.is_valid_vietnamese_word(word):\n",
    "            return word\n",
    "\n",
    "        chars = list(word)\n",
    "        tone = 0\n",
    "        vowel_indices = []\n",
    "        is_qu_or_gi = False\n",
    "        for index, char in enumerate(chars):\n",
    "            x, y = cls.vowel_to_ids.get(char, (-1, -1))\n",
    "            if x == -1:\n",
    "                continue\n",
    "            elif x == 9 and index != 0 and chars[index - 1] == 'q':  # check 'qu'\n",
    "                chars[index] = 'u'\n",
    "                is_qu_or_gi = True\n",
    "            elif x == 5 and index != 0 and chars[index - 1] == 'g':  # check 'gi'\n",
    "                chars[index] = 'i'\n",
    "                is_qu_or_gi = True\n",
    "            if y != 0:\n",
    "                tone = y\n",
    "                chars[index] = cls.vowel_map[x][0]\n",
    "            if not is_qu_or_gi or index != 1:\n",
    "                vowel_indices.append(index)\n",
    "\n",
    "        if len(vowel_indices) < 2:\n",
    "            if is_qu_or_gi:\n",
    "                if len(chars) == 2:\n",
    "                    x, y = cls.vowel_to_ids.get(chars[1])\n",
    "                    chars[1] = cls.vowel_map[x][tone]\n",
    "                else:\n",
    "                    x, y = cls.vowel_to_ids.get(chars[2], (-1, -1))\n",
    "                    if x != -1:\n",
    "                        chars[2] = cls.vowel_map[x][tone]\n",
    "                    else:\n",
    "                        chars[1] = cls.vowel_map[5][tone] if chars[1] == 'i' else cls.vowel_map[9][tone]\n",
    "                return ''.join(chars)\n",
    "            return word\n",
    "\n",
    "        for index in vowel_indices:\n",
    "            x, y = cls.vowel_to_ids[chars[index]]\n",
    "            if x == 4 or x == 8:  # ê, ơ\n",
    "                chars[index] = cls.vowel_map[x][tone]\n",
    "                return ''.join(chars)\n",
    "\n",
    "        if len(vowel_indices) == 2:\n",
    "            if vowel_indices[-1] == len(chars) - 1:\n",
    "                x, y = cls.vowel_to_ids[chars[vowel_indices[0]]]\n",
    "                chars[vowel_indices[0]] = cls.vowel_map[x][tone]\n",
    "            else:\n",
    "                x, y = cls.vowel_to_ids[chars[vowel_indices[1]]]\n",
    "                chars[vowel_indices[1]] = cls.vowel_map[x][tone]\n",
    "        else:\n",
    "            x, y = cls.vowel_to_ids[chars[vowel_indices[1]]]\n",
    "            chars[vowel_indices[1]] = cls.vowel_map[x][tone]\n",
    "        return ''.join(chars)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def standardize_sentence_tone(cls, sentence):\n",
    "        sentence = sentence.lower()\n",
    "        words = sentence.split()\n",
    "        for index, word in enumerate(words):\n",
    "            if not word:\n",
    "                return \" \"\n",
    "            cleaned_word = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "            if len(cleaned_word) == 3:\n",
    "                cleaned_word[1] = cls.standardize_vietnamese_tone(cleaned_word[1])\n",
    "            words[index] = ''.join(cleaned_word)\n",
    "        return ' '.join(words)\n",
    "\n",
    "    @classmethod\n",
    "    def fix_repeated_chars(cls, sentence): \n",
    "        return re.sub(r'(.)\\1{2,}', r'\\1', sentence)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, text):\n",
    "        text = cls.unicode_normalize(text)\n",
    "        text = cls.standardize_sentence_tone(text)\n",
    "        text = cls.fix_repeated_chars(text)\n",
    "        return text\n",
    "\n",
    "VietnameseTextPreprocessor.initialize_vowel_to_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.564674Z",
     "iopub.status.busy": "2024-11-11T17:29:28.564371Z",
     "iopub.status.idle": "2024-11-11T17:29:28.579024Z",
     "shell.execute_reply": "2024-11-11T17:29:28.578110Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.564641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, processor, text_model, image_model, tokenizer, device):\n",
    "        self.device = device\n",
    "        self.processor = processor\n",
    "        self.text_model = text_model\n",
    "        self.image_model = image_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        \"\"\"Helper function to load an image from a specified path.\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Image not found at path: {image_path}\")\n",
    "        return image\n",
    "\n",
    "    def _process_image(self, image):\n",
    "        \"\"\"Helper function to process and prepare image tensors for feature extraction.\"\"\"\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.image_model(**inputs)\n",
    "        return outputs.logits.cpu().numpy().squeeze()\n",
    "\n",
    "    def extract_image_features(self, image_name, path_prefix=\"\"):\n",
    "        \"\"\"Extract features from a list of images.\"\"\"\n",
    "        image_features = []\n",
    "        image_path = path_prefix + image_name\n",
    "        try:\n",
    "            image = self._load_image(image_path)\n",
    "            features = self._process_image(image)\n",
    "            image_features.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_name}': {str(e)}\")\n",
    "            image_features.append(np.zeros(1000)) \n",
    "        return np.array(image_features)\n",
    "\n",
    "    def _tokenize_text(self, text):\n",
    "        \"\"\"Helper function to tokenize and encode text for feature extraction.\"\"\"\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.text_model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).cpu().numpy().squeeze()\n",
    "\n",
    "    def extract_text_features(self, text):\n",
    "        \"\"\"Extract features from a list of text inputs.\"\"\"\n",
    "        text_features = [] \n",
    "        try:\n",
    "            features = self._tokenize_text(text)\n",
    "            text_features.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {str(e)}\")\n",
    "            text_features.append(np.zeros(1024))  \n",
    "        return np.array(text_features)\n",
    "\n",
    "    def extract_features(self, texts, caption_texts, images, path_prefix=\"\"):\n",
    "        \"\"\"\n",
    "        Extract both text and image features.\n",
    "        \n",
    "        Parameters:\n",
    "        - texts: List of primary text inputs.\n",
    "        - caption_texts: List of texts used as captions for images.\n",
    "        - images: List of image file names.\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of arrays (text_features, image_features, caption_text_features).\n",
    "        \"\"\"\n",
    "        image_features = self.extract_image_features(images, path_prefix=path_prefix)\n",
    "        text_features = self.extract_text_features(texts)\n",
    "        caption_features = self.extract_text_features(caption_texts)\n",
    "        \n",
    "        return text_features, image_features, caption_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SarcasmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.581024Z",
     "iopub.status.busy": "2024-11-11T17:29:28.580476Z",
     "iopub.status.idle": "2024-11-11T17:29:28.594153Z",
     "shell.execute_reply": "2024-11-11T17:29:28.593388Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.580981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SarcasmModel:\n",
    "    def __init__(self, config, n_classes, combined_layer_size, is_caption=False):\n",
    "        self.config = config\n",
    "        self.n_classes = n_classes\n",
    "        self.is_caption = is_caption\n",
    "        self.combined_layer_size = combined_layer_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Define inputs\n",
    "        image_input = Input(shape=(self.config.image_dim,), name='image_input')\n",
    "        text_input = Input(shape=(self.config.text_dim,), name='text_input')\n",
    "        \n",
    "        # Create branches\n",
    "        image_branch = self._create_branch(image_input, self.config.image_branch_layers)\n",
    "        text_branch = self._create_branch(text_input, self.config.text_branch_layers)\n",
    "\n",
    "        # Optional caption branch\n",
    "        if self.is_caption:\n",
    "            caption_input = Input(shape=(self.config.caption_dim,), name='caption_input')\n",
    "            caption_branch = self._create_branch(caption_input, self.config.caption_branch_layers)\n",
    "            combined = concatenate([image_branch, text_branch, caption_branch])\n",
    "            inputs = [image_input, text_input, caption_input]\n",
    "        else:\n",
    "            combined = concatenate([image_branch, text_branch])\n",
    "            inputs = [image_input, text_input]\n",
    "        \n",
    "        # Combine layers\n",
    "        combined = Dense(self.combined_layer_size, activation='relu')(combined)\n",
    "        combined = Dropout(self.config.dropout_rate)(combined)\n",
    "        combined = Dense(int(self.combined_layer_size/2), activation='relu')(combined)\n",
    "        combined = Dropout(self.config.dropout_rate)(combined) \n",
    "        \n",
    "        # Output layer\n",
    "        output = Dense(self.n_classes, activation='softmax', name=\"output\")(combined)\n",
    "        \n",
    "        return Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    def _create_branch(self, input_layer, layer_sizes):\n",
    "        x = input_layer\n",
    "        for size in layer_sizes:\n",
    "            x = Dense(size, activation='relu')(x)\n",
    "            x = Dropout(self.config.dropout_rate)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.595534Z",
     "iopub.status.busy": "2024-11-11T17:29:28.595212Z",
     "iopub.status.idle": "2024-11-11T17:29:28.609147Z",
     "shell.execute_reply": "2024-11-11T17:29:28.608308Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.595503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestingModel:\n",
    "    def __init__(self, model, map_label, is_caption=False):\n",
    "        self.model = model \n",
    "        self.map_label = map_label\n",
    "        self.is_caption = is_caption\n",
    "\n",
    "    def decode_labels(self, one_hot_labels):\n",
    "        reverse_mapping = {v: k for k, v in self.map_label.items()}\n",
    "        return [reverse_mapping[idx] for idx in np.argmax(one_hot_labels, axis=1)]\n",
    "\n",
    "    def dict_labels(self, list_probs):\n",
    "        return {label: prob for label, prob in zip(self.map_label.keys(), list_probs[0])}\n",
    "\n",
    "    def predict(self, image_features, text_features, caption_features=None):\n",
    "        # Check if caption features are included\n",
    "        if self.is_caption and caption_features is not None:\n",
    "            predictions = self.model.predict(\n",
    "                [image_features, text_features, caption_features],\n",
    "                verbose=0\n",
    "            )\n",
    "        else:\n",
    "            predictions = self.model.predict(\n",
    "                [image_features, text_features],\n",
    "                verbose=0\n",
    "            )\n",
    "        \n",
    "        list_prods = predictions.tolist() \n",
    "        dic_pro_label = self.dict_labels(list_prods)\n",
    "        return self.decode_labels(predictions), dic_pro_label\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "        print(f\"Model saved at {path}\")\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(path, compile=False)\n",
    "        print(f\"Model loaded from {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.610576Z",
     "iopub.status.busy": "2024-11-11T17:29:28.610302Z",
     "iopub.status.idle": "2024-11-11T17:29:28.622693Z",
     "shell.execute_reply": "2024-11-11T17:29:28.621937Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.610545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.test_path = '/kaggle/input/vimmsd/test-images/'\n",
    "        self.test_json_path = '/kaggle/input/vimmsd/vimmsd-private-test-new-translate.csv'\n",
    "        self.image_dim = 1000\n",
    "        self.text_dim = 1024\n",
    "        self.caption_dim = 1024\n",
    "        self.image_branch_layers = [1024, 512]\n",
    "        self.text_branch_layers = [512, 256]\n",
    "        self.caption_branch_layers = [512, 256]\n",
    "        self.combined_layer_size = 1024\n",
    "        self.dropout_rate = 0.3\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Prints all configuration parameters.\"\"\"\n",
    "        for key, value in self.__dict__.items():\n",
    "            print(f\"{key}: {value}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.624624Z",
     "iopub.status.busy": "2024-11-11T17:29:28.623786Z",
     "iopub.status.idle": "2024-11-11T17:29:28.636711Z",
     "shell.execute_reply": "2024-11-11T17:29:28.635834Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.624591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class WeightEnsembleVoting:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, list_of_dicts):\n",
    "        \"\"\"\n",
    "        Predicts the final label based on weighted ensemble voting from multiple models.\n",
    "\n",
    "        Parameters:\n",
    "            list_of_dicts (list of dict): A list of dictionaries containing class probabilities\n",
    "                                          from different models, e.g., [{\"a\": 0.5}, {\"a\": 0.3, \"c\": 0.8}].\n",
    "\n",
    "        Returns:\n",
    "            final_label (str): The label with the highest average probability across all models.\n",
    "            max_prob (float): The highest average probability for the chosen label.\n",
    "        \"\"\"\n",
    "        combined_dict = {}\n",
    "        for prob_dict in list_of_dicts:\n",
    "            for label, prob in prob_dict.items():\n",
    "                if label in combined_dict:\n",
    "                    combined_dict[label].append(prob)\n",
    "                else:\n",
    "                    combined_dict[label] = [prob]\n",
    "\n",
    "        averaged_dict = {label: np.mean(probs) for label, probs in combined_dict.items()}\n",
    "\n",
    "        final_label = max(averaged_dict, key=averaged_dict.get)\n",
    "        max_prob = averaged_dict[final_label]\n",
    "\n",
    "        return final_label, max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.640398Z",
     "iopub.status.busy": "2024-11-11T17:29:28.640065Z",
     "iopub.status.idle": "2024-11-11T17:29:28.681259Z",
     "shell.execute_reply": "2024-11-11T17:29:28.680400Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.640367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.682828Z",
     "iopub.status.busy": "2024-11-11T17:29:28.682466Z",
     "iopub.status.idle": "2024-11-11T17:29:28.691201Z",
     "shell.execute_reply": "2024-11-11T17:29:28.690435Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.682774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:28.692638Z",
     "iopub.status.busy": "2024-11-11T17:29:28.692302Z",
     "iopub.status.idle": "2024-11-11T17:29:43.588875Z",
     "shell.execute_reply": "2024-11-11T17:29:43.588047Z",
     "shell.execute_reply.started": "2024-11-11T17:29:28.692601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-384\")\n",
    "image_model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-384\").to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v3\")\n",
    "text_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", \n",
    "                                            trust_remote_code=True,\n",
    "                                            torch_dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:43.590556Z",
     "iopub.status.busy": "2024-11-11T17:29:43.590263Z",
     "iopub.status.idle": "2024-11-11T17:29:43.596255Z",
     "shell.execute_reply": "2024-11-11T17:29:43.595197Z",
     "shell.execute_reply.started": "2024-11-11T17:29:43.590525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(processor, text_model, image_model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:43.597586Z",
     "iopub.status.busy": "2024-11-11T17:29:43.597311Z",
     "iopub.status.idle": "2024-11-11T17:29:43.744483Z",
     "shell.execute_reply": "2024-11-11T17:29:43.743608Z",
     "shell.execute_reply.started": "2024-11-11T17:29:43.597555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "map_label2 = {\n",
    "    'not-sarcasm': 0,\n",
    "    'multi-sarcasm': 1\n",
    "}\n",
    "\n",
    "map_label3 = {\n",
    "    'image-sarcasm': 1,\n",
    "    'text-sarcasm': 2,\n",
    "    'multi-sarcasm': 0\n",
    "}\n",
    "\n",
    "map_label3_not = {\n",
    "    'image-sarcasm': 1,\n",
    "    'text-sarcasm': 2,\n",
    "    'not-sarcasm': 0\n",
    "}\n",
    "\n",
    "map_label4 = {\n",
    "    'not-sarcasm': 0,\n",
    "    'image-sarcasm': 1,\n",
    "    'text-sarcasm': 2,\n",
    "    'multi-sarcasm': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:30:09.143658Z",
     "iopub.status.busy": "2024-11-11T17:30:09.143252Z",
     "iopub.status.idle": "2024-11-11T17:30:09.804122Z",
     "shell.execute_reply": "2024-11-11T17:30:09.803226Z",
     "shell.execute_reply.started": "2024-11-11T17:30:09.143619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wev = WeightEnsembleVoting()\n",
    "\n",
    "model2 = SarcasmModel(config, 2, 1024, is_caption=True).model\n",
    "model2 = TestingModel(model2, map_label2, is_caption=True)\n",
    "model2.load_model(\"/kaggle/input/weight-best-model/best_2class_new.h5\")\n",
    "\n",
    "# model3 = SarcasmModel(config, 3, 768).model\n",
    "# model3 = TestingModel(model3, map_label3)\n",
    "# model3.load_model(\"/kaggle/input/weight-best-model/best_3class_multi_image_text.h5\")\n",
    "\n",
    "# model3_not = SarcasmModel(config, 3, 768).model\n",
    "# model3_not = TestingModel(model3_not, map_label3_not)\n",
    "# model3_not.load_model(\"/kaggle/input/weight-best-model/best_3class_not_image_text.h5\")\n",
    "\n",
    "# model4 = SarcasmModel(config, 4, 768).model\n",
    "# model4 = TestingModel(model4, map_label4)\n",
    "# model4.load_model(\"/kaggle/input/weight-best-model/best_4class_44.44.h5\")\n",
    "\n",
    "model4_caption = SarcasmModel(config, 4, 1024, is_caption=True).model\n",
    "model4_caption = TestingModel(model4_caption, map_label4, is_caption=True)\n",
    "model4_caption.load_model(\"/kaggle/input/weight-best-model/best_4class_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:29:45.014740Z",
     "iopub.status.busy": "2024-11-11T17:29:45.014424Z",
     "iopub.status.idle": "2024-11-11T17:29:45.095493Z",
     "shell.execute_reply": "2024-11-11T17:29:45.094569Z",
     "shell.execute_reply.started": "2024-11-11T17:29:45.014707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(config.test_json_path)\n",
    "\n",
    "test_df['caption'] = test_df['caption'].apply(VietnameseTextPreprocessor.unicode_normalize)\n",
    "test_df['caption'] = test_df['caption'].apply(VietnameseTextPreprocessor.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:30:12.557276Z",
     "iopub.status.busy": "2024-11-11T17:30:12.556417Z",
     "iopub.status.idle": "2024-11-11T17:36:37.920581Z",
     "shell.execute_reply": "2024-11-11T17:36:37.919620Z",
     "shell.execute_reply.started": "2024-11-11T17:30:12.557222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "results = {}\n",
    "list_prob = []\n",
    "labels = []\n",
    "for i in tqdm(test_df.index):\n",
    "    image = test_df.image[i]\n",
    "    caption = test_df.caption[i]\n",
    "    caption_image = test_df.caption_image[i]\n",
    "    text_test_features, image_test_features, caption_image_test_features  = feature_extractor.extract_features(caption, caption_image, image, config.test_path)\n",
    "    pred2, dict_pred2 = model2.predict(image_test_features, text_test_features, caption_image_test_features)\n",
    "    # pred3_not, dict_pred3_not = model3_not.predict(image_test_features, text_test_features)\n",
    "    # pred3, dict_pred3 = model3.predict(image_test_features, text_test_features)\n",
    "    # pred4, dict_pred4 = model4.predict(image_test_features, text_test_features)\n",
    "    pred4_caption, dict_pred4_caption = model4_caption.predict(image_test_features, text_test_features, caption_image_test_features)\n",
    "    # temp = {}\n",
    "    # if pred2[0] == \"not-sarcasm\":\n",
    "    #     temp[\"not-sarcasm\"] = dict_pred2.get(\"not-sarcasm\")\n",
    "    # else:\n",
    "    #     pred3, dict_pred3 = model3.predict(image_test_features, text_test_features)\n",
    "    #     temp.update(dict_pred3)\n",
    "    predict, prob = wev.predict([dict_pred2, dict_pred4_caption])\n",
    "    list_prob.append(prob)\n",
    "    labels.append(predict)\n",
    "    results[str(i)] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-11T17:29:46.533567Z",
     "iopub.status.idle": "2024-11-11T17:29:46.534065Z",
     "shell.execute_reply": "2024-11-11T17:29:46.533841Z",
     "shell.execute_reply.started": "2024-11-11T17:29:46.533812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# predictions, prob, dict_pred4 = model4.predict(image_test_features, text_test_features)\n",
    "# results = {str(i): pred for i, pred in enumerate(predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:36:52.203877Z",
     "iopub.status.busy": "2024-11-11T17:36:52.203101Z",
     "iopub.status.idle": "2024-11-11T17:36:52.212246Z",
     "shell.execute_reply": "2024-11-11T17:36:52.211335Z",
     "shell.execute_reply.started": "2024-11-11T17:36:52.203838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"results\": results,\n",
    "    \"phase\": 'test'\n",
    "}\n",
    "\n",
    "with open('results1.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:36:53.583015Z",
     "iopub.status.busy": "2024-11-11T17:36:53.582121Z",
     "iopub.status.idle": "2024-11-11T17:36:53.612804Z",
     "shell.execute_reply": "2024-11-11T17:36:53.611944Z",
     "shell.execute_reply.started": "2024-11-11T17:36:53.582965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/kaggle/working/results1.json\")\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:36:59.359809Z",
     "iopub.status.busy": "2024-11-11T17:36:59.359420Z",
     "iopub.status.idle": "2024-11-11T17:36:59.366471Z",
     "shell.execute_reply": "2024-11-11T17:36:59.365542Z",
     "shell.execute_reply.started": "2024-11-11T17:36:59.359769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df[\"label\"] = labels\n",
    "test_df[\"prob\"] = list_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption Label Voting by Majority and Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:37:01.648443Z",
     "iopub.status.busy": "2024-11-11T17:37:01.647552Z",
     "iopub.status.idle": "2024-11-11T17:37:01.657063Z",
     "shell.execute_reply": "2024-11-11T17:37:01.656102Z",
     "shell.execute_reply.started": "2024-11-11T17:37:01.648403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CaptionProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def _get_duplicate_captions(self):\n",
    "        \"\"\"Find rows with duplicate 'caption'.\"\"\"\n",
    "        return self.df[self.df.duplicated('caption', keep=False)]\n",
    "\n",
    "    def _select_label(self, group):\n",
    "        \"\"\"Select the appropriate label for duplicate rows based on 'caption'.\"\"\"\n",
    "        label_counts = group['label'].value_counts()\n",
    "\n",
    "        if len(label_counts) == 1:\n",
    "            # Case where all labels are the same\n",
    "            return label_counts.idxmax()\n",
    "\n",
    "        if label_counts.iloc[0] > label_counts.iloc[1]:\n",
    "            # Case 1: One label has a higher count\n",
    "            return label_counts.idxmax()\n",
    "        \n",
    "        # Case 2: Labels have equal counts, compare average probabilities\n",
    "        mean_probs = group.groupby('label')['prob'].mean()\n",
    "        return mean_probs.idxmax()\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Process the dataframe to ensure duplicate 'caption' rows have the correct label.\"\"\"\n",
    "        duplicate_captions = self._get_duplicate_captions()\n",
    "\n",
    "        for caption, group in duplicate_captions.groupby('caption'):\n",
    "            selected_label = self._select_label(group)\n",
    "            self.df.loc[self.df['caption'] == caption, 'label'] = selected_label\n",
    "\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:37:02.004020Z",
     "iopub.status.busy": "2024-11-11T17:37:02.003662Z",
     "iopub.status.idle": "2024-11-11T17:37:02.130662Z",
     "shell.execute_reply": "2024-11-11T17:37:02.129921Z",
     "shell.execute_reply.started": "2024-11-11T17:37:02.003985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processor = CaptionProcessor(test_df)\n",
    "processed_df = processor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:37:02.614525Z",
     "iopub.status.busy": "2024-11-11T17:37:02.613781Z",
     "iopub.status.idle": "2024-11-11T17:37:02.624067Z",
     "shell.execute_reply": "2024-11-11T17:37:02.623168Z",
     "shell.execute_reply.started": "2024-11-11T17:37:02.614487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = {str(i): pred for i, pred in enumerate(list(processed_df[\"label\"]))}\n",
    "\n",
    "output = {\n",
    "    \"results\": results,\n",
    "    \"phase\": 'test'\n",
    "}\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T17:37:03.377507Z",
     "iopub.status.busy": "2024-11-11T17:37:03.376649Z",
     "iopub.status.idle": "2024-11-11T17:37:03.393101Z",
     "shell.execute_reply": "2024-11-11T17:37:03.392229Z",
     "shell.execute_reply.started": "2024-11-11T17:37:03.377463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/kaggle/working/results.json\")\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10126731,
     "datasetId": 5831781,
     "sourceId": 9873409,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10128046,
     "datasetId": 6038447,
     "sourceId": 9874590,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10122505,
     "datasetId": 6058395,
     "sourceId": 9869590,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
